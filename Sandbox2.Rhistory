first_reffs <- fetch_reffs(requestURN)
urls <- paste(reffURL, first_reffs, sep = "")
batch_urls <- split(urls, ceiling(seq_along(urls)/100))
output_list <- list()
for (i in 1:length(batch_urls)) {
counter <- 0
temp_vector <- getURIAsynchronous(batch_urls[[i]])
temp_vector <- unname(unlist(sapply(temp_vector, parse_reffs)))
temp_vector <- temp_vector[!is.na(temp_vector)]
if(length(temp_vector) == 0) break
output_list[[i]] <- temp_vector
}
second_reffs <- unlist(output_list)
urls <- paste(reffURL, second_reffs, sep = "")
batch_urls <- split(urls, ceiling(seq_along(urls)/100))
output_list <- list()
for (i in 1:length(batch_urls)) {
counter <- 0
temp_vector <- getURIAsynchronous(batch_urls[[i]])
temp_vector <- unname(unlist(sapply(temp_vector, parse_reffs)))
temp_vector <- temp_vector[!is.na(temp_vector)]
if(length(temp_vector) == 0) break
output_list[[i]] <- temp_vector
}
third_reffs <- unlist(output_list)
urls <- paste(reffURL, third_reffs, sep = "")
batch_urls <- split(urls, ceiling(seq_along(urls)/100))
output_list <- list()
for (i in 1:length(batch_urls)) {
counter <- 0
temp_vector <- getURIAsynchronous(batch_urls[[i]])
temp_vector <- unname(unlist(sapply(temp_vector, parse_reffs)))
temp_vector <- temp_vector[!is.na(temp_vector)]
if(length(temp_vector) == 0) break
output_list[[i]] <- temp_vector
}
fourth_reffs <- unlist(output_list)
if(length(fourth_reffs) != 0) {
reffs <- fourth_reffs
} else if(length(third_reffs) != 0) {
reffs <- third_reffs
} else if(length(second_reffs) != 0) {
reffs <- second_reffs
} else {
reffs <- first_reffs
}
#### fetch texts
XMLminer <- function(x){
xname <- xmlName(x)
xattrs <- xmlAttrs(x)
c(sapply(xmlChildren(x), xmlValue), name = xname, xattrs)}
XMLpassage1 <-function(xdata){
if (xdata == "NotRetrieved") {return(xdata)
} else {result <- xmlParse(xdata)
result <- as.data.frame(t(xpathSApply(result, "//*/tei:body", XMLminer)), stringsAsFactors = FALSE)[[1]]
result <- gsub("\n", "", result, fixed = FALSE)
result <- gsub("\t", "", result, fixed = FALSE)
return(result)}}
urls <- paste(baseURL, reffs, sep = "")
t1 <- Sys.time()
batch_urls <- split(urls, ceiling(seq_along(urls)/100))
output_list <- vector("list", length(batch_urls))
for (i in 1:length(batch_urls)) {
counter <- 0
temp_vector <- getURIAsynchronous(batch_urls[[i]])
while(length(which(temp_vector == "")) > 0) {
if (counter == 3) {temp_vector[which(temp_vector == "")] <- "NotRetrieved"}; if (counter == 3) break; counter <- counter+1;
print(paste("Fetch rest of batch-request ", as.character(i), "/", as.character(length(batch_urls)), sep=""));
temp_vector[which(temp_vector == "")] <- getURIAsynchronous(batch_urls[[i]][which(temp_vector == "")])}
temp_vector <- unlist(lapply(temp_vector, XMLpassage1))
output_list[[i]] <- temp_vector
print(paste("Fetched ", as.character(i), "/", as.character(length(batch_urls)), sep=""))
}
urls <- paste(baseURL, reffs, sep = "")
t1 <- Sys.time()
batch_urls <- split(urls, ceiling(seq_along(urls)/100))
output_list <- vector("list", length(batch_urls))
for (i in 1:length(batch_urls)) {
counter <- 0
temp_vector <- getURIAsynchronous(batch_urls[[i]])
while(length(which(temp_vector == "")) > 0) {
if (counter == 3) {temp_vector[which(temp_vector == "")] <- "NotRetrieved"}; if (counter == 3) break; counter <- counter+1;
print(paste("Fetch rest of batch-request ", as.character(i), "/", as.character(length(batch_urls)), sep=""));
temp_vector[which(temp_vector == "")] <- getURIAsynchronous(batch_urls[[i]][which(temp_vector == "")])}
temp_vector <- unlist(lapply(temp_vector, XMLpassage1))
output_list[[i]] <- temp_vector
rm(temp_vector)
print(paste("Fetched ", as.character(i), "/", as.character(length(batch_urls)), sep=""))
}
shiny::runApp('OneDrive/GithubProjects/ToPan')
shiny::runApp('OneDrive/GithubProjects/ToPan')
shiny::runApp('OneDrive/GithubProjects/ToPan')
shiny::runApp('OneDrive/GithubProjects/ToPan')
runApp('OneDrive/GithubProjects/ToPan')
shiny::runApp('OneDrive/GithubProjects/ToPan')
runApp('OneDrive/GithubProjects/ToPan')
runApp('OneDrive/GithubProjects/ToPan')
shiny::runApp('OneDrive/GithubProjects/ToPan')
runApp('OneDrive/GithubProjects/ToPan')
runApp('OneDrive/GithubProjects/ToPan')
library(XML)
library(httr)
baseURL <- "http://cts.perseids.org/api/cts/?request=GetPassage&urn="
reffURL <- "http://cts.perseids.org/api/cts/?request=GetValidReff&urn="
requestURN <- "urn:cts:latinLit:phi1002.phi001.perseus-eng2"
fetch_reffs <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(reffURL, x, sep = "")
URLcontent <- tryCatch({getURLContent(URL)},
error = function(err)
{result <- "NoReturn"
return(result)})
reffs <- unlist(strsplit(URLcontent, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
parse_reffs <- function(x){
reffs <- unlist(strsplit(x, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
first_reffs <- fetch_reffs(requestURN)
urls <- paste(reffURL, first_reffs, sep = "")
batch_urls <- split(urls, ceiling(seq_along(urls)/100))
output_list <- list()
for (i in 1:length(batch_urls)) {
print("ha")
temp_vector <- GET(batch_urls[[i]])
temp_vector <- unname(unlist(sapply(temp_vector, parse_reffs)))
temp_vector <- temp_vector[!is.na(temp_vector)]
if(length(temp_vector) == 0) break
output_list[[i]] <- temp_vector}
batch_urls
GET(batch_urls)
first_reffs <- fetch_reffs(requestURN)
urls <- paste(reffURL, first_reffs, sep = "")
GET(urls)
urls
first_reffs <- fetch_reffs(requestURN)
GET(requestURN)
library(XML)
library(httr)
baseURL <- "http://cts.perseids.org/api/cts/?request=GetPassage&urn="
reffURL <- "http://cts.perseids.org/api/cts/?request=GetValidReff&urn="
requestURN <- "urn:cts:latinLit:phi1002.phi001.perseus-eng2"
fetch_reffs <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(reffURL, x, sep = "")
URLcontent <- tryCatch({GET(URL)},
error = function(err)
{result <- "NoReturn"
return(result)})
reffs <- unlist(strsplit(URLcontent, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
parse_reffs <- function(x){
reffs <- unlist(strsplit(x, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
first_reffs <- fetch_reffs(requestURN)
URL <- paste(reffURL, requestURN, sep = "")
GET(url = URL)
GET(URL)
GET(URL)$response
content(GET(URL))
content(GET(URL), type = "text/xml")
library(XML)
library(httr)
baseURL <- "http://cts.perseids.org/api/cts/?request=GetPassage&urn="
reffURL <- "http://cts.perseids.org/api/cts/?request=GetValidReff&urn="
requestURN <- "urn:cts:latinLit:phi1002.phi001.perseus-eng2"
fetch_reffs <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(reffURL, x, sep = "")
URLcontent <- content(GET(URL), type = "text/xml")
reffs <- unlist(strsplit(URLcontent, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
parse_reffs <- function(x){
reffs <- unlist(strsplit(x, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
first_reffs <- fetch_reffs(requestURN)
content(GET(URL), type = "text/xml")
URLcontent <- content(GET(URL), type = "text/xml")
URLcontent
xmlTreeParse(URLcontent)
what <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
xmltop <- xmlRoot(what)
xmltop
xmltop$reply
xmltop$request
xmltop$request[1]
xmltop[[1]]
xmltop[[2]]
xmltop[[2]][[2]]
xmltop[[2]][[1]]
xmltop[[2]][[1]][[1:]]
xmltop[[2]][[1]][[1]]
xmltop[[2]][[1]]
as.character(xmltop[[2]][[1]])
unlist(strsplit(as.character(xmltop[[2]][[1]]), split="<urn>|</urn>"))
unlist(strsplit(as.character(xmltop[[2]][[1]]), split="<urn>|</urn>"))[1]
unlist(strsplit(as.character(xmltop[[2]][[1]]), split="<urn>|</urn>"))[2]
unlist(strsplit(as.character(xmltop[[2]][[1]]), split="<urn>|</urn>"))[3]
unlist(strsplit(as.character(xmltop[[2]][[1]]), split="<urn>|</urn>"))[4]
xmltop[[2]][[1]]
length(xmltop[[2]][[1]])
URL
URLcontent <- content(GET(URL), type = "text/xml")
URLcontent
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
xmltop[1][1]
xmltop[1][2]
xmltop[2][2]
xmltop[2][1]
xmltop[2]
xmltop[2][2]
xmltop[2][1]
xmltop[2][1][1]
xmltop[2][1][2]
xmltop[[2]]
xmltop[[2]][[1]]
xmltop[[2]][[1]][[1]]
xmlAttrs(xmltop[[2]][[1]])
xmlAttrs(xmltop[[2]][[1]][[1]])
xmlAttrs(xmltop[[2]][[1]][[1]])["urn"]
xmlAttrs(xmltop[[2]][[1]])["urn"]
xmlAttrs(xmltop[[2]])
xmlAttrs(xmltop)
xmlNamespace(xmltop)
xmlNamespace(xmltop[[2]])
xmlNamespace(xmltop[[2]][[1]])
xmlNamespace(xmltop[[2]][[1]][[1]])
xmlValue(xmltop[[2]][[1]][[1]])
xmlValue(xmltop[[2]][[1]])
xmlValue(xmltop[[2]][[1]], sep = " ")
xmlValue(xmltop[[2]])
xmlValue(xmltop)
doc = xmlParseDoc(xmlfile)
pathSApply(doc,"/reply",xmlValue)
xpathSApply(doc,"/reply",xmlValue)
xpathSApply(xmlfile,"/reply",xmlValue)
xpathSApply(xmlfile,"/reply/",xmlValue)
getChildrenStrings(xmlfile)
getChildrenStrings(xmltop)
xmlValue(xmltop[[2]][[1]])
xmlValue(xmltop[[2]][[1]][[1]])
xmlValue(xmltop[[2]][[1]][[2]])
xmlValue(xmltop[[2]][[1]][[13]])
xmlValue(xmltop[[2]][[1]][[14]])
length(xmltop[[2]][[1]])
library(XML)
library(httr)
baseURL <- "http://cts.perseids.org/api/cts/?request=GetPassage&urn="
reffURL <- "http://cts.perseids.org/api/cts/?request=GetValidReff&urn="
requestURN <- "urn:cts:latinLit:phi1002.phi001.perseus-eng2"
fetch_reffs <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(reffURL, x, sep = "")
URLcontent <- content(GET(URL), type = "text/xml")
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
reffs <- vector()
for (i in 1:length(xmltop[[2]][[1]])) {
reffs[i] <- xmlValue(xmltop[[2]][[1]][[i]])
}
return(reffs)
}
parse_reffs <- function(x){
reffs <- unlist(strsplit(x, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
first_reffs <- fetch_reffs(requestURN)
urls <- paste(reffURL, first_reffs, sep = "")
urls
GET(urls)
install.packages("https://github.com/jeroenooms/curl/archive/master.tar.gz", repos = NULL)
library(curl)
?multi
?multipleClasses
?multi
??multi
GET(urls)
GET(urls, multi = TRUE)
library(curl)
install.packages("https://github.com/jeroenooms/curl/archive/master.tar.gz", repos = NULL)
install.packages("https://github.com/jeroenooms/curl/archive/master.tar.gz", repos = NULL)
library(curl)
?multi
library(XML)
library(httr)
baseURL <- "http://cts.perseids.org/api/cts/?request=GetPassage&urn="
reffURL <- "http://cts.perseids.org/api/cts/?request=GetValidReff&urn="
requestURN <- "urn:cts:latinLit:phi1002.phi001.perseus-eng2"
fetch_reffs <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(reffURL, x, sep = "")
URLcontent <- content(GET(URL), type = "text/xml")
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
reffs <- vector()
for (i in 1:length(xmltop[[2]][[1]])) {
reffs[i] <- xmlValue(xmltop[[2]][[1]][[i]])
}
return(reffs)
}
parse_reffs <- function(x){
reffs <- unlist(strsplit(x, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
first_reffs <- fetch_reffs(requestURN)
urls <- paste(reffURL, first_reffs, sep = "")
urls
GET(urls)
?curl_fetch_memory
curl_fetch_memory(urls)
multi_run(urls)
multi(urls)
?multi
curl(urls)
curl(urls[1])
curl(urls[2])
curl(urls, multi)
multi_add(urls)
?multi
GET(urls)
install.packages("rvest")
library(rvest)
lego_movie <- read_html("http://www.imdb.com/title/tt1490017/")
lego_movie
read_html(urls)
library(XML)
library(httr)
baseURL <- "http://cts.perseids.org/api/cts/?request=GetPassage&urn="
reffURL <- "http://cts.perseids.org/api/cts/?request=GetValidReff&urn="
requestURN <- "urn:cts:latinLit:phi1002.phi001.perseus-eng2"
fetch_reffs <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(reffURL, x, sep = "")
URLcontent <- content(GET(URL), type = "text/xml")
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
reffs <- vector()
for (i in 1:length(xmltop[[2]][[1]])) {
reffs[i] <- xmlValue(xmltop[[2]][[1]][[i]])
}
return(reffs)
}
parse_reffs <- function(x){
reffs <- unlist(strsplit(x, split="<urn>|</urn>"))
reffs <- reffs[2:length(reffs)]
reffs <- reffs[seq(1, length(reffs), 2)]
return(reffs)
}
first_reffs <- fetch_reffs(requestURN)
first_reffs
raw.result <- GET(url = reffURL, path = first_reffs)
raw.result
GET("http://www.google.com/search", query=list(q="httr"), timeout(seconds = 0.5))
GET("http://www.google.com/search", query=list(q="httr"))
GET("http://www.google.com/search", query=list(q=c("httr", "rcurl"))
)
GET("http://www.google.com/search", query=list(q="httr", b="rcurl"))
GET("http://www.google.com/search", query=list(q="httr", b="rcurl"))[[2]]
GET("http://www.google.com/search", query=list(q="httr", b="rcurl"))[[1]]
GET("http://www.google.com/search", query=list(q="httr", b="rcurl"))[1]
GET("http://www.google.com/search", query=list(q="httr", b="rcurl"))[3]
GET("http://www.google.com/search", query=list(q="httr", b="rcurl"))
GET(reffURL, query=list(q="httr", b="rcurl"))
GET(reffURL, query=list(urn="first_reffs[1]"))
GET(reffURL, query=list(urn=first_reffs[1]))
conten(GET(reffURL, query=list(urn=first_reffs[1])))
content(GET(reffURL, query=list(urn=first_reffs[1])))
second_reffs <- lapply(first_reffs, fetch_reffs)
second_reffs
unlist(second_reffs)
third_reffs <- unlist(lapply(second_reffs, fetch_reffs))
second_reffs <- unlist(lapply(first_reffs, fetch_reffs))
second_reffs
second_reffs[1]
length(second_reffs)
third_reffs <- unlist(lapply(second_reffs, fetch_reffs))
fourth_reffs <- unlist(lapply(third_reffs, fetch_reffs))
first_reffs
second_reffs
third_reffs
fourth_reffs <- unlist(lapply(third_reffs[1:10], fetch_reffs))
fourth_reffs
fetch_reffs <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(reffURL, x, sep = "")
URLcontent <- content(GET(URL), type = "text/xml")
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
reffs <- vector()
if(xmlValue(xmltop[[2]][[1]][[1]]) == "Internal Server Error"){
return("Internal Server Error")
}
for (i in 1:length(xmltop[[2]][[1]])) {
reffs[i] <- xmlValue(xmltop[[2]][[1]][[i]])
}
return(reffs)
}
fourth_reffs <- unlist(lapply(third_reffs[1:10], fetch_reffs))
test_reffs <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(reffURL, x, sep = "")
URLcontent <- content(GET(URL), type = "text/xml")
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
if(xmlValue(xmltop[[2]][[1]][[1]]) == "Internal Server Error"){
return(FALSE)
}
return(TRUE)
}
test_reffs(first_reffs[1])
test_reffs(first_reffs[2])
test_reffs(first_reffs[1])
test_reffs(second_reffs[1])
test_reffs(third_reffs[1])
test_reffs(whatever)
whatever <- vector()
test_reffs(whatever)
first_reffs <- fetch_reffs(requestURN)
if (test_reffs(first_reffs[1]) == TRUE) {
second_reffs <- unlist(lapply(first_reffs, fetch_reffs))
} else {second_reffs <- vector()}
if (test_reffs(second_reffs[1]) == TRUE) {
third_reffs <- unlist(lapply(second_reffs, fetch_reffs))
} else {third_reffs <- vector()}
if (test_reffs(third_reffs[1]) == TRUE) {
fourth_reffs <- unlist(lapply(third_reffs[1:10], fetch_reffs))
} else {fourth_reffs <- vector()}
test_reffs(third_reffs[1])
fetch_reffs(third_reffs[1])
fetch_reffs(third_reffs[2])
third_reffs
fourth_reffs
test_urns <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(baseURL, x, sep = "")
URLcontent <- content(GET(URL), type = "text/xml")
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
if(xmlValue(xmltop[[2]][[1]][[1]]) == "Internal Server Error"){
return(FALSE)
}
return(TRUE)
}
test_urns(second_reffs[1])
test_urns(third_reffs[1])
test_urns(fourth_reffs[1])
fetch_passage <- function(x){
message("Retrieve Reffs for ", x)
URL <- paste(baseURL, x, sep = "")
URLcontent <- content(GET(URL), type = "text/xml")
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
reffs <- vector()
for (i in 1:length(xmltop[[2]][[1]])) {
reffs[i] <- xmlValue(xmltop[[2]][[1]][[i]])
}
return(reffs)
}
fetch_passage(third_reffs[1])
URL <- paste(baseURL, "urn:cts:latinLit:phi1002.phi001.perseus-eng2:pr.pr.1", sep = "")
URL
URLcontent <- content(GET(URL), type = "text/xml")
xmlfile <- xmlTreeParse(URLcontent)
xmltop <- xmlRoot(xmlfile)
length(xmltop[[2]][[1]]
)
xmltop
xmltop[[1]]
xmltop[[2]]
xmltop[[2]][[1]]
xmltop[[2]][[2]]
xmltop[[2]][[3]]
xmltop[[2]][[1]]
xmltop[[2]][[2]]
xmltop[[2]][[2]][[1]]
xmltop[[2]][[2]][[2]]
xmltop[[2]][[2]][[1]]
xmltop[[2]][[2]][[1]][[1]]
xmltop[[2]][[2]][[1]][[1]][[1]]
xmltop[[2]][[2]][[1]][[1]][[1]][[1]]
xmltop[[2]][[2]][[1]][[1]][[1]][[1]][[1]]
xmltop[[2]][[2]][[1]][[1]][[1]][[1]][[1]][[[1]]]
xmltop[[2]][[2]][[1]][[1]][[1]][[1]][[1]][[1]]
xmltop[[2]][[2]][[1]][[1]][[1]][[1]][[1]][[1]][[1]]
xmltop[[2]][[2]][[1]][[1]][[1]][[1]][[1]][[1]][[1]][[1]]
xmltop[[2]][[2]][[1]][[1]][[1]][[1]][[1]][[1]][[1]][[1]][[1]]
xmltop[[2]]
save.image("~/OneDrive/GithubProjects/ToPan/Sandbox2.RData")
savehistory("~/OneDrive/GithubProjects/ToPan/Sandbox2.Rhistory")
